"""
RAG (Retrieval-Augmented Generation) æ¨¡å—
ä½¿ç”¨ FAISS å‘é‡æ£€ç´¢ + åŒ»ç–—çŸ¥è¯†åº“
"""

import os
import json
import logging
import numpy as np
from pathlib import Path
from typing import List, Dict, Optional

logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥ RAG ç›¸å…³åº“
try:
    import faiss
    from sentence_transformers import SentenceTransformer
    RAG_AVAILABLE = True
    logger.info("RAG dependencies loaded successfully")
except ImportError as e:
    RAG_AVAILABLE = False
    logger.warning(f"RAG dependencies not available: {e}")


class RAGModule:
    """RAG æ£€ç´¢å¢å¼ºç”Ÿæˆæ¨¡å—"""
    
    def __init__(self, 
                 embedding_model: str = "BAAI/bge-small-zh-v1.5",
                 index_path: str = "data/rag_index",
                 knowledge_base_path: str = "data/knowledge_base.json",
                 device: str = "cpu",
                 top_k: int = 3,
                 min_score: float = 0.5):
        """
        åˆå§‹åŒ– RAG æ¨¡å—
        
        Args:
            embedding_model: Embedding æ¨¡å‹åç§°
            index_path: FAISS ç´¢å¼•ä¿å­˜è·¯å¾„
            knowledge_base_path: çŸ¥è¯†åº“ JSON æ–‡ä»¶è·¯å¾„
            device: è¿è¡Œè®¾å¤‡
            top_k: é»˜è®¤æ£€ç´¢æ•°é‡
            min_score: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„ç»“æœå°†è¢«è¿‡æ»¤
        """
        self.top_k = top_k
        self.min_score = min_score
        self.index_path = Path(index_path)
        self.knowledge_base_path = Path(knowledge_base_path)
        self.documents = []  # å­˜å‚¨åŸå§‹æ–‡æ¡£
        self.index = None    # FAISS ç´¢å¼•
        self.model = None    # Embedding æ¨¡å‹
        self.knowledge_graph = None  # çŸ¥è¯†å›¾è°±æ¨¡å—
        
        if not RAG_AVAILABLE:
            logger.warning("RAG module initialized but dependencies not available")
            return
        
        try:
            # åŠ è½½ Embedding æ¨¡å‹
            logger.info(f"Loading embedding model: {embedding_model}")
            
            # ä¼˜å…ˆä½¿ç”¨ ModelScope ä¸‹è½½æ¨¡å‹
            if 'BAAI' in embedding_model or 'bge' in embedding_model.lower():
                try:
                    from modelscope import snapshot_download
                    # ä» ModelScope ä¸‹è½½ bge æ¨¡å‹
                    models_dir = Path(__file__).parent.parent / "models" / "embedding"
                    models_dir.mkdir(parents=True, exist_ok=True)
                    ms_model_name = "AI-ModelScope/bge-small-zh-v1.5"
                    logger.info(f"Downloading {ms_model_name} from ModelScope...")
                    model_path = snapshot_download(ms_model_name, cache_dir=str(models_dir))
                    logger.info(f"Embedding model downloaded to: {model_path}")
                    self.model = SentenceTransformer(model_path, device=device)
                except ImportError:
                    logger.warning("modelscope not available, falling back to HuggingFace")
                    self.model = SentenceTransformer(embedding_model, device=device)
                except Exception as e:
                    logger.warning(f"ModelScope download failed: {e}, falling back to HuggingFace")
                    self.model = SentenceTransformer(embedding_model, device=device)
            else:
                self.model = SentenceTransformer(embedding_model, device=device)
            
            self.embedding_dim = self.model.get_sentence_embedding_dimension()
            logger.info(f"Embedding model loaded, dimension: {self.embedding_dim}")
            
            # å°è¯•åŠ è½½å·²æœ‰ç´¢å¼•ï¼Œå¦åˆ™ä»çŸ¥è¯†åº“æ„å»º
            if self._load_index():
                logger.info("Loaded existing FAISS index")
            elif self.knowledge_base_path.exists():
                self._build_index_from_knowledge_base()
            else:
                logger.warning(f"Knowledge base not found: {self.knowledge_base_path}")
                self._create_empty_index()
                
        except Exception as e:
            logger.error(f"Failed to initialize RAG module: {e}")
            self.model = None
    
    def _create_empty_index(self):
        """åˆ›å»ºç©ºçš„ FAISS ç´¢å¼•"""
        self.index = faiss.IndexFlatIP(self.embedding_dim)  # å†…ç§¯ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        self.documents = []
        
    def _load_index(self) -> bool:
        """åŠ è½½å·²ä¿å­˜çš„ FAISS ç´¢å¼•"""
        index_file = self.index_path / "index.faiss"
        docs_file = self.index_path / "documents.json"
        
        if index_file.exists() and docs_file.exists():
            try:
                self.index = faiss.read_index(str(index_file))
                with open(docs_file, 'r', encoding='utf-8') as f:
                    self.documents = json.load(f)
                
                print("\n" + "="*50)
                print(f"ğŸ“š [RAG] æˆåŠŸåŠ è½½ç´¢å¼•")
                print(f"   - æ–‡æ¡£æ•°é‡: {len(self.documents)}")
                print(f"   - å‘é‡æ•°é‡: {self.index.ntotal}")
                print("="*50 + "\n")
                
                return True
            except Exception as e:
                logger.error(f"Failed to load index: {e}")
        return False
    
    def _save_index(self):
        """ä¿å­˜ FAISS ç´¢å¼•"""
        self.index_path.mkdir(parents=True, exist_ok=True)
        
        index_file = self.index_path / "index.faiss"
        docs_file = self.index_path / "documents.json"
        
        faiss.write_index(self.index, str(index_file))
        with open(docs_file, 'w', encoding='utf-8') as f:
            json.dump(self.documents, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Index saved to {self.index_path}")
    
    def _build_index_from_knowledge_base(self):
        """ä»çŸ¥è¯†åº“æ–‡ä»¶æ„å»ºç´¢å¼•"""
        logger.info(f"Building index from {self.knowledge_base_path}")
        
        with open(self.knowledge_base_path, 'r', encoding='utf-8') as f:
            knowledge_base = json.load(f)
        
        # æå–æ–‡æ¡£å†…å®¹
        self.documents = []
        texts = []
        
        for item in knowledge_base:
            content = item.get('content', '')
            if content:
                self.documents.append({
                    'id': item.get('id', len(self.documents)),
                    'content': content,
                    'metadata': item.get('metadata', {})
                })
                texts.append(content)
        
        if not texts:
            logger.warning("No documents found in knowledge base")
            self._create_empty_index()
            return
        
        # ç”Ÿæˆ embeddings
        logger.info(f"Generating embeddings for {len(texts)} documents...")
        embeddings = self.model.encode(texts, normalize_embeddings=True)
        
        # åˆ›å»º FAISS ç´¢å¼•
        self._create_empty_index()
        self.index.add(embeddings.astype(np.float32))
        
        # ä¿å­˜ç´¢å¼•
        self._save_index()
        logger.info(f"Index built with {len(self.documents)} documents")
    
    def add_documents(self, documents: List[Dict]):
        """
        æ·»åŠ æ–‡æ¡£åˆ°ç´¢å¼•
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£åŒ…å« 'content' å­—æ®µ
        """
        if not self.model:
            logger.error("RAG model not initialized")
            return
        
        texts = []
        for doc in documents:
            content = doc.get('content', '')
            if content:
                self.documents.append({
                    'id': doc.get('id', len(self.documents)),
                    'content': content,
                    'metadata': doc.get('metadata', {})
                })
                texts.append(content)
        
        if texts:
            embeddings = self.model.encode(texts, normalize_embeddings=True)
            self.index.add(embeddings.astype(np.float32))
            self._save_index()
            logger.info(f"Added {len(texts)} documents to index")
    
    def retrieve(self, query: str, top_k: int = None) -> List[Dict]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›çš„æ–‡æ¡£æ•°é‡
            
        Returns:
            æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        """
        if not self.model or not self.index or self.index.ntotal == 0:
            return []
        
        top_k = top_k or self.top_k
        top_k = min(top_k, self.index.ntotal)
        
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.model.encode([query], normalize_embeddings=True)
        
        # æ£€ç´¢
        scores, indices = self.index.search(query_embedding.astype(np.float32), top_k)
        
        # æ‰“å°æ£€ç´¢ä¿¡æ¯åˆ°ç»ˆç«¯ (RAG è°ƒè¯•ä¿¡æ¯)
        print("\n" + "="*50)
        print(f"ğŸ” [RAG æ£€ç´¢] æŸ¥è¯¢: {query}")
        print(f"   ç›¸ä¼¼åº¦é˜ˆå€¼: {self.min_score}")
        print("-" * 50)
        
        # è¿”å›ç»“æœï¼ˆåº”ç”¨ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤ï¼‰
        results = []
        filtered_count = 0
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx < len(self.documents):
                # æ£€æŸ¥æ˜¯å¦æ»¡è¶³ç›¸ä¼¼åº¦é˜ˆå€¼
                if score < self.min_score:
                    filtered_count += 1
                    if i < 3:
                        content_preview = self.documents[idx]['content'].replace('\n', ' ')[:60]
                        label = self.documents[idx].get('metadata', {}).get('label', 'æœªçŸ¥')
                        print(f"  [âœ—] (ç›¸ä¼¼åº¦: {score:.3f} < {self.min_score}) [{label}]")
                        print(f"      {content_preview}... (å·²è¿‡æ»¤)")
                    continue
                
                doc = self.documents[idx].copy()
                doc['score'] = float(score)
                results.append(doc)
                
                # æ‰“å°å‰3æ¡æœ‰æ•ˆæ£€ç´¢ç»“æœ
                if len(results) <= 3:
                    content_preview = doc['content'].replace('\n', ' ')[:100]
                    label = doc.get('metadata', {}).get('label', 'æœªçŸ¥')
                    print(f"  [âœ“] (ç›¸ä¼¼åº¦: {score:.3f}) [{label}]")
                    print(f"      {content_preview}...")
        
        if filtered_count > 0:
            print(f"\n   âš  å·²è¿‡æ»¤ {filtered_count} æ¡ä½ç›¸ä¼¼åº¦ç»“æœ")
        if not results:
            print("   ğŸ“­ æ— æœ‰æ•ˆæ£€ç´¢ç»“æœï¼ˆæ‰€æœ‰ç»“æœç›¸ä¼¼åº¦ä½äºé˜ˆå€¼ï¼‰")
        
        print("="*50 + "\n")
        
        return results
    
    def build_context(self, query: str, top_k: int = None) -> str:
        """
        æ„å»º RAG ä¸Šä¸‹æ–‡ï¼ˆå‘é‡æ£€ç´¢ + çŸ¥è¯†å›¾è°±ï¼‰
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            top_k: æ£€ç´¢æ•°é‡
            
        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        context_parts = []
        
        # 1. å‘é‡æ£€ç´¢
        retrieved = self.retrieve(query, top_k)
        if retrieved:
            context_parts.append("ã€å‘é‡æ£€ç´¢ç»“æœã€‘")
            for i, doc in enumerate(retrieved[:3], 1):
                context_parts.append(f"å‚è€ƒ{i}ï¼š{doc['content']}")
        
        # 2. çŸ¥è¯†å›¾è°±è¡¥å……
        if self.knowledge_graph and self.knowledge_graph.enabled:
            kg_context = self.knowledge_graph.build_context_from_query(query)
            if kg_context:
                context_parts.append("\nã€çŸ¥è¯†å›¾è°±è¡¥å……ã€‘")
                context_parts.append(kg_context)
        
        return "\n".join(context_parts)
    
    def get_info(self) -> Dict:
        """è·å–æ¨¡å—ä¿¡æ¯"""
        return {
            "available": RAG_AVAILABLE and self.model is not None,
            "document_count": len(self.documents),
            "index_size": self.index.ntotal if self.index else 0,
            "embedding_dim": self.embedding_dim if self.model else None,
            "top_k": self.top_k
        }


# ç®€åŒ–ç‰ˆ RAGï¼ˆç”¨äºæµ‹è¯•æˆ–ä¾èµ–ä¸å¯ç”¨æ—¶ï¼‰
class SimpleRAGModule:
    """ç®€åŒ–çš„ RAG æ¨¡å—ï¼ˆåŸºäºå…³é”®è¯åŒ¹é…ï¼‰"""
    
    def __init__(self, knowledge_base_path: str = "data/knowledge_base.json"):
        self.documents = []
        self.knowledge_base_path = Path(knowledge_base_path)
        
        if self.knowledge_base_path.exists():
            try:
                with open(self.knowledge_base_path, 'r', encoding='utf-8') as f:
                    kb = json.load(f)
                self.documents = [item.get('content', '') for item in kb if item.get('content')]
                logger.info(f"SimpleRAG loaded {len(self.documents)} documents")
            except Exception as e:
                logger.error(f"Failed to load knowledge base: {e}")
    
    def retrieve(self, query: str, top_k: int = 3) -> List[Dict]:
        """åŸºäºå…³é”®è¯çš„ç®€å•æ£€ç´¢"""
        results = []
        
        for i, doc in enumerate(self.documents):
            # è®¡ç®—å…³é”®è¯åŒ¹é…å¾—åˆ†
            score = sum(1 for char in query if char in doc)
            if score > 0:
                results.append({
                    'id': i,
                    'content': doc,
                    'score': score
                })
        
        # æŒ‰å¾—åˆ†æ’åº
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:top_k]
    
    def build_context(self, query: str, top_k: int = 3) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡"""
        retrieved = self.retrieve(query, top_k)
        
        if not retrieved:
            return ""
        
        context_parts = [f"å‚è€ƒ{i}ï¼š{doc['content']}" for i, doc in enumerate(retrieved, 1)]
        return "\n".join(context_parts)
    
    def get_info(self) -> Dict:
        return {
            "available": True,
            "document_count": len(self.documents),
            "type": "simple_keyword_matching"
        }


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    # æµ‹è¯• RAG æ¨¡å—
    rag = RAGModule()
    
    print(f"RAG Info: {rag.get_info()}")
    
    # æµ‹è¯•æ£€ç´¢
    query = "æ„Ÿå†’æ€ä¹ˆåŠ"
    results = rag.retrieve(query)
    print(f"\nQuery: {query}")
    for r in results:
        print(f"  - {r['content'][:50]}... (score: {r['score']:.3f})")