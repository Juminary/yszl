"""
æ¨¡å‹ä¸‹è½½è„šæœ¬
ä¸‹è½½é¡¹ç›®æ‰€éœ€çš„æ‰€æœ‰æ¨¡å‹åˆ°å¯¹åº”æ–‡ä»¶å¤¹
å¦‚æœæ¨¡å‹å·²å­˜åœ¨åˆ™è·³è¿‡
"""

import os
import sys
import logging
from pathlib import Path

logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æ¨¡å‹é…ç½®
MODELS_DIR = Path(__file__).parent / "models"

# éœ€è¦ä¸‹è½½çš„æ¨¡å‹åˆ—è¡¨
MODELS = {
    # å¯¹è¯æ¨¡å‹ (Qwen3-4B from ModelScope)
    "dialogue": {
        "name": "Qwen/Qwen3-4B-Instruct-2507",
        "source": "modelscope",
        "path": MODELS_DIR / "Qwen" / "Qwen3-4B-Instruct-2507",
        "description": "å¯¹è¯ç”Ÿæˆæ¨¡å‹ (4Bå‚æ•°)"
    },
    # ASRæ¨¡å‹ (FunASR Paraformer)
    "asr": {
        "name": "iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
        "source": "modelscope",
        "path": MODELS_DIR / "models" / "iic" / "speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
        "description": "è¯­éŸ³è¯†åˆ«æ¨¡å‹ (Paraformer)"
    },
    # VADæ¨¡å‹
    "vad": {
        "name": "iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
        "source": "modelscope",
        "path": MODELS_DIR / "models" / "iic" / "speech_fsmn_vad_zh-cn-16k-common-pytorch",
        "description": "è¯­éŸ³æ´»åŠ¨æ£€æµ‹æ¨¡å‹"
    },
    # æ ‡ç‚¹æ¨¡å‹
    "punc": {
        "name": "iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
        "source": "modelscope",
        "path": MODELS_DIR / "models" / "iic" / "punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
        "description": "æ ‡ç‚¹æ¢å¤æ¨¡å‹"
    },
    # å£°çº¹è¯†åˆ«æ¨¡å‹
    "speaker": {
        "name": "iic/speech_campplus_sv_zh-cn_16k-common",
        "source": "modelscope",
        "path": MODELS_DIR / "models" / "iic" / "speech_campplus_sv_zh-cn_16k-common",
        "description": "å£°çº¹è¯†åˆ«æ¨¡å‹"
    },
    # SenseVoice (å¯é€‰)
    "sensevoice": {
        "name": "iic/SenseVoiceSmall",
        "source": "modelscope",
        "path": MODELS_DIR / "models" / "iic" / "SenseVoiceSmall",
        "description": "å¤šè¯­è¨€è¯­éŸ³è¯†åˆ«æ¨¡å‹"
    },
    # Embeddingæ¨¡å‹ (for RAG)
    "embedding": {
        "name": "BAAI/bge-small-zh-v1.5",
        "source": "huggingface",
        "path": None,  # HuggingFaceä¼šè‡ªåŠ¨ç¼“å­˜
        "description": "RAGå‘é‡åµŒå…¥æ¨¡å‹"
    }
}


def check_model_exists(model_config):
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨"""
    path = model_config.get("path")
    if path is None:
        return False
    
    if path.exists():
        # æ£€æŸ¥ç›®å½•æ˜¯å¦æœ‰å†…å®¹
        files = list(path.iterdir()) if path.is_dir() else []
        return len(files) > 0
    return False


def download_from_modelscope(model_name, cache_dir):
    """ä» ModelScope ä¸‹è½½æ¨¡å‹"""
    try:
        from modelscope import snapshot_download
        
        path = snapshot_download(model_name, cache_dir=str(cache_dir))
        return path
    except Exception as e:
        logger.error(f"ModelScope ä¸‹è½½å¤±è´¥: {e}")
        return None


def download_from_huggingface(model_name):
    """ä» HuggingFace ä¸‹è½½æ¨¡å‹"""
    try:
        from sentence_transformers import SentenceTransformer
        
        # å¯¹äº embedding æ¨¡å‹ä½¿ç”¨ sentence_transformers
        if "bge" in model_name.lower():
            model = SentenceTransformer(model_name)
            return True
        
        # å…¶ä»–æ¨¡å‹ä½¿ç”¨ transformers
        from transformers import AutoTokenizer, AutoModel
        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        model = AutoModel.from_pretrained(model_name, trust_remote_code=True)
        return True
        
    except Exception as e:
        logger.error(f"HuggingFace ä¸‹è½½å¤±è´¥: {e}")
        return None


def download_model(key, config):
    """ä¸‹è½½å•ä¸ªæ¨¡å‹"""
    name = config["name"]
    source = config["source"]
    description = config["description"]
    
    print(f"\n{'='*50}")
    print(f"ğŸ“¦ {description}")
    print(f"   æ¨¡å‹: {name}")
    print(f"   æ¥æº: {source}")
    print(f"{'='*50}")
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    if check_model_exists(config):
        logger.info(f"âœ“ æ¨¡å‹å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
        return "å·²å­˜åœ¨"
    
    # ä¸‹è½½æ¨¡å‹
    logger.info(f"å¼€å§‹ä¸‹è½½...")
    
    if source == "modelscope":
        result = download_from_modelscope(name, MODELS_DIR)
    elif source == "huggingface":
        result = download_from_huggingface(name)
    else:
        logger.error(f"æœªçŸ¥çš„æ¨¡å‹æ¥æº: {source}")
        return "å¤±è´¥"
    
    if result:
        logger.info(f"âœ“ ä¸‹è½½å®Œæˆ")
        return "æˆåŠŸ"
    else:
        return "å¤±è´¥"


def setup_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    directories = [
        MODELS_DIR,
        MODELS_DIR / "Qwen",
        MODELS_DIR / "models" / "iic",
        Path(__file__).parent.parent / "data",
        Path(__file__).parent.parent / "data" / "rag_index",
        Path(__file__).parent / "logs",
        Path(__file__).parent / "temp",
    ]
    
    for path in directories:
        path.mkdir(parents=True, exist_ok=True)
    
    logger.info("ç›®å½•ç»“æ„å·²åˆ›å»º")


def main():
    """ä¸»å‡½æ•°"""
    print()
    print("="*60)
    print("  ğŸ¥ åŒ»ç–—è¯­éŸ³åŠ©æ‰‹ - æ¨¡å‹ä¸‹è½½å·¥å…·")
    print("="*60)
    print()
    
    # åˆ›å»ºç›®å½•
    setup_directories()
    
    # é€‰æ‹©è¦ä¸‹è½½çš„æ¨¡å‹
    print("å¯ç”¨æ¨¡å‹:")
    for i, (key, config) in enumerate(MODELS.items(), 1):
        status = "âœ“" if check_model_exists(config) else "â—‹"
        print(f"  {i}. [{status}] {config['description']}")
    
    print()
    print("é€‰é¡¹:")
    print("  a - ä¸‹è½½æ‰€æœ‰æ¨¡å‹")
    print("  s - åªä¸‹è½½ç¼ºå¤±çš„æ¨¡å‹")
    print("  q - é€€å‡º")
    print()
    
    choice = input("è¯·é€‰æ‹© [s]: ").strip().lower() or "s"
    
    if choice == "q":
        print("å·²å–æ¶ˆ")
        return
    
    # ç¡®å®šè¦ä¸‹è½½çš„æ¨¡å‹
    if choice == "a":
        models_to_download = MODELS
    else:  # é»˜è®¤åªä¸‹è½½ç¼ºå¤±çš„
        models_to_download = {
            k: v for k, v in MODELS.items() 
            if not check_model_exists(v)
        }
    
    if not models_to_download:
        print("\nâœ“ æ‰€æœ‰æ¨¡å‹å·²å°±ç»ªï¼")
        return
    
    print(f"\nå°†ä¸‹è½½ {len(models_to_download)} ä¸ªæ¨¡å‹...")
    
    # ä¸‹è½½æ¨¡å‹
    results = {}
    for key, config in models_to_download.items():
        results[key] = download_model(key, config)
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "="*60)
    print("ä¸‹è½½ç»“æœ:")
    print("="*60)
    
    for key, status in results.items():
        icon = "âœ“" if status in ["æˆåŠŸ", "å·²å­˜åœ¨"] else "âœ—"
        print(f"  {icon} {MODELS[key]['description']}: {status}")
    
    print("="*60)
    
    # æ£€æŸ¥å…³é”®æ¨¡å‹
    critical = ["dialogue", "asr"]
    all_ok = all(
        results.get(k, "å¤±è´¥") in ["æˆåŠŸ", "å·²å­˜åœ¨"] or check_model_exists(MODELS[k])
        for k in critical
    )
    
    if all_ok:
        print("\nâœ“ æ ¸å¿ƒæ¨¡å‹å·²å°±ç»ªï¼Œå¯ä»¥å¯åŠ¨æœåŠ¡å™¨ï¼")
        print("  è¿è¡Œ: ./start_server.sh")
    else:
        print("\nâš  éƒ¨åˆ†å…³é”®æ¨¡å‹æœªå°±ç»ªï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    
    print()


if __name__ == "__main__":
    main()
