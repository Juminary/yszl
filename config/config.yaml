# 服务器配置
server:
  host: "0.0.0.0"
  port: 6008
  debug: false

# 客户端配置
client:
  server_url: "http://localhost:6008"

# 语音识别配置 (SenseVoice - 多语言/方言支持)
asr:
  model: "iic/SenseVoiceSmall"
  provider: "funasr"
  device: "cpu"  # 使用GPU加速
  language: "auto"  # 自动语言检测

# 情感识别配置 (SenseVoice)
emotion:
  model: "iic/SenseVoiceSmall"
  provider: "funasr"
  device: "cpu"  # 使用GPU加速
  classes: ["neutral", "happy", "sad", "angry", "fear", "surprise"]

# 声纹识别配置 (Cam++)
speaker:
  model: "iic/speech_campplus_sv_zh-cn_16k-common"
  provider: "modelscope"
  threshold: 0.5  # 降低阈值以提高识别率
  device: "cpu"  # 使用GPU加速
  db_path: "data/speaker_db.pkl"

# 对话系统配置 (支持 GGUF 量化模型)
dialogue:
  # 模型提供者: transformers (HuggingFace), gguf (llama.cpp), gptq (GPTQ量化)
  provider: "gptq"
  
  # GGUF 配置 (当 provider=gguf 时使用)
  gguf_repo: "Qwen/Qwen3-4B-GGUF"     # ModelScope 仓库
  gguf_file: "qwen3-4b-q4_k_m.gguf"   # GGUF 文件名 (小写)
  gguf_source: "modelscope"           # 下载源: huggingface, modelscope
  
  # GPTQ 配置 (当 provider=gptq 时使用)
  gptq_model_path: "server/models/gptq/qwen3-8b-sft-huatuo-quant-w4a16"  # 本地GPTQ模型路径
  
  # Transformers 配置 (当 provider=transformers 时使用)
  model: "Qwen/Qwen2.5-0.5B-Instruct"
  
  # 通用参数
  max_length: 512
  temperature: 0.7
  top_p: 0.9
  device: "cuda"  # GGUF 使用 Metal 自动加速
  history_length: 10
  system_prompt: |
    你是一个专业的医疗语音助手。你需要根据用户的角色（患者或医生）提供不同的服务：
    
    对于患者：
    - 耐心倾听症状描述
    - 提供初步的导诊建议
    - 解释医学术语，使用通俗易懂的语言
    - 给予情感关怀和安慰
    - 提醒严重症状需要立即就医
    
    对于医生：
    - 提供专业的辅助诊断建议
    - 给出可能的疾病列表和鉴别要点
    - 提供详细的用药信息
    - 使用专业医学术语
    - 提示需要的检查项目
    
    重要规则：
    一，只用纯中文回答，禁止英文、数字、字母。
    二，只用中文逗号和句号，禁止其他标点如冒号、问号、感叹号、括号、引号。
    三，禁止使用星号、井号、横线等任何符号。
    四，禁止使用列表、编号、分点格式，必须写成连贯的一段话。
    五，态度温和友好，专业但不生硬。
    六，对于医疗建议，务必提醒这只是初步参考，建议咨询专业医生。

# 语音合成配置 (CosyVoice)
tts:
  model: "iic/CosyVoice-300M-Instruct"
  provider: "modelscope"
  device: "cuda"  # 使用GPU加速
  sample_rate: 16000
  fast_mode: false  # CosyVoice模式（false=高质量，true=快速但低质量） pip install edge-tts
  streaming: true  # 启用流式TTS（边生成边播放）

# 音频处理配置
audio:
  sample_rate: 16000
  channels: 1
  chunk_size: 1024
  format: "wav"

# 声学前端增强配置 (ReSpeaker 6-Mic Circular Array HAT)
acoustic_frontend:
  # 总开关
  enabled: true
  
  # 硬件设备配置
  device:
    type: "respeaker_6mic"          # 设备类型: respeaker_6mic, respeaker_4mic, usb, default
    sample_rate: 16000              # 采样率 (Hz)
    chunk_duration_ms: 30           # 每帧时长 (ms)，影响延迟和处理粒度
    total_channels: 8               # 总通道数 (6麦克风 + 2回声)
    mic_channels: [0, 1, 2, 3, 4, 5]    # 麦克风通道索引
    echo_channels: [6, 7]               # 回声参考通道索引
    button_gpio: 26                 # 用户按钮 GPIO 引脚
  
  # 阵列几何参数 (6麦克风环形排列)
  array:
    mic_angles_deg: [0, 60, 120, 180, 240, 300]  # 各麦克风角度位置
    radius_m: 0.035                 # 阵列半径 (米)，约3.5cm
  
  # DOA 声源定位配置
  doa:
    enabled: true
    algorithm: "gcc_phat"           # 算法: gcc_phat, srp_phat, music
    fft_size: 512                   # FFT窗口大小
    num_directions: 360             # 搜索方向数 (角度分辨率)
    mic_pairs: [[0, 3], [1, 4], [2, 5]]  # 用于TDOA的麦克风对 (对角)
    smoothing_window: 5             # 时间平滑窗口大小 (帧数)
  
  # 波束成形配置
  beamforming:
    enabled: true
    method: "das"                   # 方法: das (延时求和), mvdr
    interpolation_factor: 4         # 分数延时插值倍率
    use_weights: true               # 是否使用加权
    adaptive_steering: true         # 自适应跟踪DOA方向
    smoothing_factor: 0.3           # 方向平滑系数 (0-1)
  
  # 回声消除 (AEC) 配置
  aec:
    enabled: true
    algorithm: "nlms"               # 算法: nlms, rls
    filter_length: 256              # 自适应滤波器长度 (采样点)
    step_size: 0.1                  # NLMS步长 (学习率)
    regularization: 1.0e-6          # 正则化项
    doubletalk_threshold: 0.6       # 双讲检测阈值
    enable_residual_suppression: true   # 残余回声抑制
    suppression_factor: 0.3         # 抑制因子
    use_hardware_reference: true    # 使用硬件回声参考通道 (推荐)
  
  # VAD 语音活动检测配置
  vad:
    enabled: true
    method: "energy"                # 方法: energy, silero, webrtc
    energy_threshold: 0.02          # 能量阈值 (归一化)
    min_speech_duration_ms: 100     # 最小语音持续时间 (ms)
    min_silence_duration_ms: 300    # 最小静音持续时间 (ms)
  
  # LED 环形灯配置
  led:
    enabled: true
    brightness: 15                  # 全局亮度 (0-31)
    doa_indicator: true             # 显示声源方向
    status_patterns: true           # 显示状态模式 (监听/说话/思考等)
    colors:                         # 自定义颜色 (RGB)
      listening: [100, 180, 255]    # 监听状态 - 医疗蓝
      speaking: [0, 200, 100]       # 说话状态 - 医疗绿
      thinking: [255, 200, 0]       # 思考状态 - 橙黄
      error: [255, 0, 0]            # 错误状态 - 红色

  
# 唤醒词配置
wakeword:
  enabled: true
  keyword: "你好"
  threshold: 0.8

# 日志配置
logging:
  level: "INFO"
  file: "logs/voice_assistant.log"

# 数据存储路径
paths:
  models: "models"
  data: "data"
  logs: "logs"
  temp: "temp"
rag:
  enabled: true  # 已修复本地加载问题
  embedding_model: "BAAI/bge-small-zh-v1.5"
  index_path: "data/rag_index"
  top_k: 3
  min_score: 0.6  # 相似度阈值，低于此值的结果将被过滤
  device: "cpu"

# 知识图谱配置 (Neo4j)
knowledge_graph:
  enabled: true
  host: "localhost"
  port: 7474
  user: "neo4j"
  password: "12345678"  # Neo4j 要求密码至少8个字符
