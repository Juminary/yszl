"""
éº¦å…‹é£é˜µåˆ—æ ¸å¿ƒæ¨¡å— (Microphone Array Core)

ReSpeaker 6-Mic Circular Array çš„é«˜çº§å°è£…
æ•´åˆå¤šé€šé“é‡‡é›†ã€DOAã€æ³¢æŸæˆå½¢å’ŒAECä¸ºç»Ÿä¸€æ¥å£

ç¡¬ä»¶è§„æ ¼:
- 6ä¸ªå…¨å‘éº¦å…‹é£ (MSM321A3729H9CP, -22dBFS, SNR 59dB)
- ç¯å½¢æ’åˆ—ï¼Œç›´å¾„çº¦7cm
- 2ä¸ªå›å£°å‚è€ƒé€šé“ (ç”¨äºAEC)
- é‡‡æ ·ç‡: 16kHz (æ”¯æŒ8kHz-48kHz)
"""

import numpy as np
import logging
import threading
import time
from typing import Optional, Callable, Dict, Any, Tuple, List
from dataclasses import dataclass, field
from enum import Enum
from collections import deque

logger = logging.getLogger(__name__)


class MicArrayState(Enum):
    """éº¦å…‹é£é˜µåˆ—çŠ¶æ€"""
    IDLE = "idle"
    LISTENING = "listening"
    PROCESSING = "processing"
    ERROR = "error"


@dataclass
class AudioFrame:
    """
    éŸ³é¢‘å¸§æ•°æ®ç»“æ„ - åŒ…å«æ‰€æœ‰å£°å­¦ä¿¡æ¯
    
    è¿™æ˜¯å£°å­¦å‰ç«¯çš„æ ¸å¿ƒè¾“å‡ºå•å…ƒï¼Œæ•´åˆäº†å¤šé€šé“éŸ³é¢‘ã€
    DOAä¼°è®¡ã€æ³¢æŸæˆå½¢è¾“å‡ºç­‰ä¿¡æ¯
    """
    # åŸå§‹å¤šé€šé“æ•°æ®
    raw_channels: np.ndarray      # shape: (samples, 8)
    timestamp: float              # é‡‡é›†æ—¶é—´æˆ³
    
    # åˆ†ç¦»åçš„é€šé“
    mic_channels: np.ndarray = None       # shape: (samples, 6) éº¦å…‹é£
    echo_channels: np.ndarray = None      # shape: (samples, 2) å›å£°å‚è€ƒ
    
    # å¤„ç†åè¾“å‡º
    enhanced_audio: np.ndarray = None     # shape: (samples,) æ³¢æŸå¢å¼ºå
    clean_audio: np.ndarray = None        # shape: (samples,) AECå¤„ç†å
    
    # å£°å­¦ç‰¹å¾
    doa_angle: float = None               # å£°æºæ–¹å‘ (0-360åº¦)
    doa_confidence: float = 0.0           # DOAç½®ä¿¡åº¦
    energy: float = 0.0                   # éŸ³é¢‘èƒ½é‡
    is_speech: bool = False               # VADæ£€æµ‹ç»“æœ
    
    # å…ƒæ•°æ®
    sample_rate: int = 16000
    
    def get_mono(self) -> np.ndarray:
        """è·å–å•é€šé“éŸ³é¢‘ (ä¼˜å…ˆè¿”å›å¤„ç†åçš„éŸ³é¢‘)"""
        if self.clean_audio is not None:
            return self.clean_audio
        if self.enhanced_audio is not None:
            return self.enhanced_audio
        if self.mic_channels is not None:
            return self.mic_channels[:, 0]  # è¿”å›ç¬¬ä¸€ä¸ªéº¦å…‹é£
        return self.raw_channels[:, 0]
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬ä¸ºå­—å…¸ (ç”¨äºäº‹ä»¶ä¼ é€’)"""
        return {
            "timestamp": self.timestamp,
            "doa_angle": self.doa_angle,
            "doa_confidence": self.doa_confidence,
            "energy": self.energy,
            "is_speech": self.is_speech,
            "sample_rate": self.sample_rate,
            "samples": len(self.raw_channels) if self.raw_channels is not None else 0,
        }


@dataclass 
class MicArrayConfig:
    """éº¦å…‹é£é˜µåˆ—é…ç½®"""
    # é‡‡æ ·å‚æ•°
    sample_rate: int = 16000
    chunk_duration_ms: int = 30       # æ¯å¸§æ—¶é•¿(ms)
    
    # é€šé“é…ç½® (ReSpeaker 6-Mic å›ºå®šé…ç½®)
    total_channels: int = 8
    mic_channel_indices: List[int] = field(default_factory=lambda: [0, 1, 2, 3, 4, 5])
    echo_channel_indices: List[int] = field(default_factory=lambda: [6, 7])
    
    # é˜µåˆ—å‡ ä½• (6éº¦å…‹é£ç¯å½¢é˜µåˆ—ï¼Œè§’åº¦ä½ç½®)
    mic_angles_deg: List[float] = field(default_factory=lambda: [0, 60, 120, 180, 240, 300])
    array_radius_m: float = 0.035     # é˜µåˆ—åŠå¾„ (çº¦3.5cm)
    
    # åŠŸèƒ½å¼€å…³
    enable_doa: bool = True
    enable_beamforming: bool = True  
    enable_aec: bool = True
    enable_vad: bool = True
    
    # VADå‚æ•°
    vad_threshold: float = 0.02       # èƒ½é‡é˜ˆå€¼
    vad_min_speech_ms: int = 100      # æœ€å°è¯­éŸ³é•¿åº¦
    
    @property
    def chunk_samples(self) -> int:
        """æ¯å¸§é‡‡æ ·ç‚¹æ•°"""
        return int(self.sample_rate * self.chunk_duration_ms / 1000)


class MicrophoneArray:
    """
    éº¦å…‹é£é˜µåˆ—æ ¸å¿ƒç±»
    
    æ•´åˆ ReSpeaker 6-Mic çš„æ‰€æœ‰å£°å­¦å¤„ç†åŠŸèƒ½:
    - 8é€šé“éŸ³é¢‘é‡‡é›† (6 mic + 2 echo)
    - å®æ—¶ DOA å£°æºå®šä½
    - æ³¢æŸæˆå½¢ä¿¡å·å¢å¼º
    - å›å£°æ¶ˆé™¤ (AEC)
    - ç®€å•VADæ£€æµ‹
    
    ä½¿ç”¨ç¤ºä¾‹:
    ```python
    mic = MicrophoneArray()
    mic.start()
    
    while True:
        frame = mic.read()
        if frame:
            print(f"DOA: {frame.doa_angle}Â°, Energy: {frame.energy:.4f}")
            # ä½¿ç”¨ frame.clean_audio è¿›è¡Œåç»­å¤„ç†
    
    mic.stop()
    ```
    """
    
    def __init__(self, config: MicArrayConfig = None):
        self.config = config or MicArrayConfig()
        self.state = MicArrayState.IDLE
        
        # å†…éƒ¨ç»„ä»¶ (å»¶è¿Ÿåˆå§‹åŒ–)
        self._driver = None
        self._doa = None
        self._beamformer = None
        self._aec = None
        
        # çŠ¶æ€
        self._is_running = False
        self._lock = threading.Lock()
        
        # å›è°ƒ
        self._callbacks: Dict[str, List[Callable]] = {
            "on_audio": [],        # éŸ³é¢‘å¸§å›è°ƒ
            "on_doa_update": [],   # DOAæ›´æ–°å›è°ƒ
            "on_speech_start": [], # è¯­éŸ³å¼€å§‹
            "on_speech_end": [],   # è¯­éŸ³ç»“æŸ
        }
        
        # VADçŠ¶æ€
        self._speech_active = False
        self._speech_frames_count = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        self._frame_count = 0
        self._last_doa = None
        
        logger.info(f"MicrophoneArray initialized: {self.config.sample_rate}Hz, "
                   f"{self.config.chunk_duration_ms}ms chunks")
    
    def _init_components(self):
        """åˆå§‹åŒ–å†…éƒ¨ç»„ä»¶"""
        # å¯¼å…¥é©±åŠ¨
        from .respeaker_driver import ReSpeakerDriver, ReSpeakerConfig
        
        driver_config = ReSpeakerConfig(
            sample_rate=self.config.sample_rate,
            channels=self.config.total_channels,
            chunk_size=self.config.chunk_samples,
        )
        self._driver = ReSpeakerDriver(driver_config)
        
        # DOAä¼°è®¡å™¨
        if self.config.enable_doa:
            try:
                from .doa import DOAEstimator
                self._doa = DOAEstimator(
                    sample_rate=self.config.sample_rate,
                    mic_angles=self.config.mic_angles_deg,
                    array_radius=self.config.array_radius_m,
                )
                logger.info("DOA estimator enabled")
            except Exception as e:
                logger.warning(f"DOA initialization failed: {e}")
                self._doa = None
        
        # æ³¢æŸæˆå½¢å™¨
        if self.config.enable_beamforming:
            try:
                from .beamformer import Beamformer
                self._beamformer = Beamformer(
                    sample_rate=self.config.sample_rate,
                    mic_angles=self.config.mic_angles_deg,
                    array_radius=self.config.array_radius_m,
                )
                logger.info("Beamformer enabled")
            except Exception as e:
                logger.warning(f"Beamformer initialization failed: {e}")
                self._beamformer = None
        
        # å›å£°æ¶ˆé™¤å™¨
        if self.config.enable_aec:
            try:
                from .aec import AcousticEchoCanceller
                self._aec = AcousticEchoCanceller(
                    sample_rate=self.config.sample_rate,
                )
                logger.info("AEC enabled")
            except Exception as e:
                logger.warning(f"AEC initialization failed: {e}")
                self._aec = None
    
    def start(self):
        """å¯åŠ¨éº¦å…‹é£é˜µåˆ—"""
        with self._lock:
            if self._is_running:
                logger.warning("MicrophoneArray already running")
                return
            
            self._init_components()
            
            if self._driver:
                self._driver.start()
                self._is_running = True
                self.state = MicArrayState.LISTENING
                logger.info("MicrophoneArray started")
            else:
                self.state = MicArrayState.ERROR
                logger.error("Failed to start: driver not available")
    
    def stop(self):
        """åœæ­¢éº¦å…‹é£é˜µåˆ—"""
        with self._lock:
            self._is_running = False
            if self._driver:
                self._driver.stop()
            self.state = MicArrayState.IDLE
            logger.info("MicrophoneArray stopped")
    
    def read(self, timeout: float = 1.0) -> Optional[AudioFrame]:
        """
        è¯»å–ä¸€å¸§å¤„ç†åçš„éŸ³é¢‘
        
        Args:
            timeout: è¶…æ—¶æ—¶é—´(ç§’)
            
        Returns:
            AudioFrame å¯¹è±¡ï¼ŒåŒ…å«æ‰€æœ‰å£°å­¦ä¿¡æ¯
        """
        if not self._is_running or not self._driver:
            return None
        
        # ä»é©±åŠ¨è¯»å–åŸå§‹éŸ³é¢‘
        raw_audio = self._driver.read(timeout=timeout)
        if raw_audio is None:
            return None
        
        # åˆ›å»ºéŸ³é¢‘å¸§
        frame = AudioFrame(
            raw_channels=raw_audio,
            timestamp=time.time(),
            sample_rate=self.config.sample_rate,
        )
        
        # å¤„ç†éŸ³é¢‘å¸§
        self._process_frame(frame)
        
        # æ›´æ–°ç»Ÿè®¡
        self._frame_count += 1
        
        # è§¦å‘å›è°ƒ
        self._emit("on_audio", frame)
        
        return frame
    
    def _process_frame(self, frame: AudioFrame):
        """å¤„ç†éŸ³é¢‘å¸§ - æ‰§è¡ŒDOAã€æ³¢æŸæˆå½¢ã€AEC"""
        
        # 1. åˆ†ç¦»é€šé“
        frame.mic_channels = frame.raw_channels[:, self.config.mic_channel_indices]
        frame.echo_channels = frame.raw_channels[:, self.config.echo_channel_indices]
        
        # 2. è®¡ç®—èƒ½é‡
        frame.energy = np.sqrt(np.mean(frame.mic_channels.astype(np.float32) ** 2))
        
        # 3. DOAä¼°è®¡
        if self._doa:
            doa_angle, confidence = self._doa.estimate(frame.mic_channels)
            frame.doa_angle = doa_angle
            frame.doa_confidence = confidence
            
            # DOAå˜åŒ–æ—¶è§¦å‘å›è°ƒ
            if self._last_doa is None or abs(doa_angle - self._last_doa) > 10:
                self._emit("on_doa_update", frame)
                self._last_doa = doa_angle
        
        # 4. æ³¢æŸæˆå½¢ (æŒ‡å‘DOAæ–¹å‘)
        if self._beamformer and frame.doa_angle is not None:
            frame.enhanced_audio = self._beamformer.process(
                frame.mic_channels, 
                target_angle=frame.doa_angle
            )
        else:
            # é™çº§: ä½¿ç”¨ç¬¬ä¸€ä¸ªéº¦å…‹é£
            frame.enhanced_audio = frame.mic_channels[:, 0].astype(np.float32)
        
        # 5. å›å£°æ¶ˆé™¤
        if self._aec:
            # ä½¿ç”¨å›å£°é€šé“ä½œä¸ºå‚è€ƒ
            echo_ref = frame.echo_channels[:, 0].astype(np.float32)
            frame.clean_audio = self._aec.process(frame.enhanced_audio, echo_ref)
        else:
            frame.clean_audio = frame.enhanced_audio
        
        # 6. VADæ£€æµ‹
        if self.config.enable_vad:
            frame.is_speech = frame.energy > self.config.vad_threshold
            self._update_vad_state(frame)
    
    def _update_vad_state(self, frame: AudioFrame):
        """æ›´æ–°VADçŠ¶æ€æœº"""
        min_frames = int(self.config.vad_min_speech_ms / self.config.chunk_duration_ms)
        
        if frame.is_speech:
            self._speech_frames_count += 1
            if not self._speech_active and self._speech_frames_count >= min_frames:
                self._speech_active = True
                self._emit("on_speech_start", frame)
        else:
            if self._speech_active:
                self._speech_active = False
                self._speech_frames_count = 0
                self._emit("on_speech_end", frame)
            else:
                self._speech_frames_count = 0
    
    def on(self, event: str, callback: Callable):
        """
        æ³¨å†Œäº‹ä»¶å›è°ƒ
        
        Args:
            event: äº‹ä»¶åç§° (on_audio, on_doa_update, on_speech_start, on_speech_end)
            callback: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ AudioFrame å‚æ•°
        """
        if event in self._callbacks:
            self._callbacks[event].append(callback)
    
    def off(self, event: str, callback: Callable):
        """å–æ¶ˆäº‹ä»¶å›è°ƒ"""
        if event in self._callbacks and callback in self._callbacks[event]:
            self._callbacks[event].remove(callback)
    
    def _emit(self, event: str, data: Any):
        """è§¦å‘äº‹ä»¶"""
        for callback in self._callbacks.get(event, []):
            try:
                callback(data)
            except Exception as e:
                logger.error(f"Callback error for {event}: {e}")
    
    def set_reference_audio(self, audio: np.ndarray):
        """
        è®¾ç½®AECå‚è€ƒä¿¡å· (TTSæ’­æ”¾æ—¶è°ƒç”¨)
        
        Args:
            audio: TTSè¾“å‡ºçš„éŸ³é¢‘æ•°æ®
        """
        if self._aec:
            self._aec.set_reference(audio)
    
    def get_current_doa(self) -> Optional[float]:
        """è·å–å½“å‰å£°æºæ–¹å‘"""
        return self._last_doa
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "state": self.state.value,
            "is_running": self._is_running,
            "frame_count": self._frame_count,
            "current_doa": self._last_doa,
            "speech_active": self._speech_active,
            "components": {
                "doa": self._doa is not None,
                "beamformer": self._beamformer is not None,
                "aec": self._aec is not None,
            }
        }
    
    def __enter__(self):
        self.start()
        return self
    
    def __exit__(self, *args):
        self.stop()


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================

def create_mic_array(
    sample_rate: int = 16000,
    enable_doa: bool = True,
    enable_beamforming: bool = True,
    enable_aec: bool = True,
) -> MicrophoneArray:
    """
    åˆ›å»ºéº¦å…‹é£é˜µåˆ—å®ä¾‹çš„ä¾¿æ·å‡½æ•°
    
    Args:
        sample_rate: é‡‡æ ·ç‡
        enable_doa: æ˜¯å¦å¯ç”¨DOA
        enable_beamforming: æ˜¯å¦å¯ç”¨æ³¢æŸæˆå½¢
        enable_aec: æ˜¯å¦å¯ç”¨å›å£°æ¶ˆé™¤
        
    Returns:
        é…ç½®å¥½çš„ MicrophoneArray å®ä¾‹
    """
    config = MicArrayConfig(
        sample_rate=sample_rate,
        enable_doa=enable_doa,
        enable_beamforming=enable_beamforming,
        enable_aec=enable_aec,
    )
    return MicrophoneArray(config)


def create_from_config(config_path: str = None) -> MicrophoneArray:
    """
    ä»é…ç½®æ–‡ä»¶åˆ›å»ºéº¦å…‹é£é˜µåˆ—
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º config/config.yaml
        
    Returns:
        é…ç½®å¥½çš„ MicrophoneArray å®ä¾‹
    """
    import os
    import yaml
    
    # é»˜è®¤é…ç½®è·¯å¾„
    if config_path is None:
        # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
        possible_paths = [
            "config/config.yaml",
            "../config/config.yaml",
            "../../config/config.yaml",
            os.path.join(os.path.dirname(__file__), "../../config/config.yaml"),
        ]
        for path in possible_paths:
            if os.path.exists(path):
                config_path = path
                break
    
    if config_path is None or not os.path.exists(config_path):
        logger.warning(f"Config file not found, using defaults")
        return create_mic_array()
    
    # åŠ è½½é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        full_config = yaml.safe_load(f)
    
    af_config = full_config.get('acoustic_frontend', {})
    
    if not af_config.get('enabled', True):
        logger.info("acoustic_frontend disabled in config")
        return None
    
    # è§£æé…ç½®
    device_cfg = af_config.get('device', {})
    array_cfg = af_config.get('array', {})
    doa_cfg = af_config.get('doa', {})
    bf_cfg = af_config.get('beamforming', {})
    aec_cfg = af_config.get('aec', {})
    vad_cfg = af_config.get('vad', {})
    
    # æ„å»º MicArrayConfig
    config = MicArrayConfig(
        sample_rate=device_cfg.get('sample_rate', 16000),
        chunk_duration_ms=device_cfg.get('chunk_duration_ms', 30),
        total_channels=device_cfg.get('total_channels', 8),
        mic_channel_indices=device_cfg.get('mic_channels', [0, 1, 2, 3, 4, 5]),
        echo_channel_indices=device_cfg.get('echo_channels', [6, 7]),
        mic_angles_deg=array_cfg.get('mic_angles_deg', [0, 60, 120, 180, 240, 300]),
        array_radius_m=array_cfg.get('radius_m', 0.035),
        enable_doa=doa_cfg.get('enabled', True),
        enable_beamforming=bf_cfg.get('enabled', True),
        enable_aec=aec_cfg.get('enabled', True),
        enable_vad=vad_cfg.get('enabled', True),
        vad_threshold=vad_cfg.get('energy_threshold', 0.02),
        vad_min_speech_ms=vad_cfg.get('min_speech_duration_ms', 100),
    )
    
    logger.info(f"Loaded acoustic_frontend config from {config_path}")
    return MicrophoneArray(config)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    def on_doa(frame: AudioFrame):
        print(f"DOA updated: {frame.doa_angle:.1f}Â° (confidence: {frame.doa_confidence:.2f})")
    
    def on_speech_start(frame: AudioFrame):
        print("ğŸ¤ Speech started")
    
    def on_speech_end(frame: AudioFrame):
        print("ğŸ”‡ Speech ended")
    
    mic = create_mic_array()
    mic.on("on_doa_update", on_doa)
    mic.on("on_speech_start", on_speech_start)
    mic.on("on_speech_end", on_speech_end)
    
    with mic:
        print("Listening for 10 seconds...")
        print("Speak and move around to test DOA!")
        
        for i in range(int(10 * 1000 / 30)):  # 10ç§’
            frame = mic.read()
            if frame and i % 10 == 0:  # æ¯300msæ‰“å°ä¸€æ¬¡
                print(f"Energy: {frame.energy:.4f}, DOA: {frame.doa_angle or 'N/A'}")
    
    print("Stats:", mic.get_stats())
